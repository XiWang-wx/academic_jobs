{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "job_list.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZNwP8FpqREp"
      },
      "source": [
        "# Academic Job Search Automation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbIDO0tjIgHo"
      },
      "source": [
        "import requests\n",
        "import json\n",
        "import bs4\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import time\n",
        "from IPython.core.display import Pretty\n",
        "from datetime import datetime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPQub4Yzp4EV",
        "outputId": "72e18059-b78a-40b4-d043-fffc33b4c14e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pd.set_option('display.max_colwidth', -1)\n",
        "pd.set_option('display.max_rows', 200)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wN4f_k3DX7de"
      },
      "source": [
        "### 1. H-Net Job Guide "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DbAfCPaiSz_"
      },
      "source": [
        "hnet_URL = \"https://www.h-net.org/jobs/job_browse.php\"\n",
        "hnet_page = requests.get(hnet_URL)\n",
        "hnet_soup = BeautifulSoup(hnet_page.text, \"html.parser\")\n",
        "\n",
        "institution = []\n",
        "position = []\n",
        "link = []\n",
        "post_date = []\n",
        "\n",
        "if hnet_soup.find(name='p', string='September 2021'):\n",
        "    month_post = hnet_soup.find(name='p', string='September 2021').next_sibling.next_sibling\n",
        "else: pass\n",
        "\n",
        "for a in month_post.find_all(name='a'):\n",
        "  institution.append(a.parent.next_element.replace(\", \", \"\"))\n",
        "  position.append(a.text)\n",
        "  link.append('https://www.h-net.org/jobs/' + a['href'])\n",
        "\n",
        "  date_str = a.find_next('span')['title']\n",
        "  date = datetime.strptime(date_str, '%A, %d %B %Y, %X %p').date()\n",
        "  post_date.append(date)\n",
        "\n",
        "d = {'Institution':institution, 'Position': position, 'Link': link, 'Posting Date': post_date}\n",
        "df_hnet = pd.DataFrame(d)\n",
        "df_hnet = df_hnet.drop_duplicates(subset=['Link'])\n",
        "\n",
        "df_hnet = df_hnet.reset_index(drop=True)\n",
        "df_hnet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qpCWw1xMeoZ"
      },
      "source": [
        "#SELECT THE INDEX NUMBER FROM THE LIST ABOVE\n",
        "select_list = []\n",
        "df_hnet = df_hnet.iloc[select_list]\n",
        "\n",
        "deadline = []\n",
        "discipline = []\n",
        "\n",
        "for i in list(df_hnet['Link']):\n",
        "    post = requests.get(i)\n",
        "    post_soup = BeautifulSoup(post.text, \"html.parser\")\n",
        "    td1 = post_soup.find('td', string='Closing Date')\n",
        "    date_str = td1.find_next().text\n",
        "    date = datetime.strptime(date_str, '%m/%d/%Y')\n",
        "    deadline.append(date)\n",
        "\n",
        "    td3 = post_soup.find('td', string='Primary Category:')\n",
        "    discipline.append(td3.find_next().text)\n",
        "\n",
        "d = {'Deadline':deadline, 'Discipline': discipline}\n",
        "df_hnet_add = pd.DataFrame(d)\n",
        "\n",
        "df_hnet=df_hnet.reset_index(drop=True)\n",
        "df_hnet=pd.concat([df_hnet, df_hnet_add], axis=1)\n",
        "df_hnet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVs5mn96iVoL"
      },
      "source": [
        "### 1.1 H-Net Search by Category"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GyAk0K5YFRr"
      },
      "source": [
        "#SELECT YOUR CATEGORY NUMBER IN \"my_cat_list=\"\n",
        "my_cat_list = ['10','11','12','104','29','32','38']\n",
        "\n",
        "institution = []\n",
        "position = []\n",
        "post_date = []\n",
        "link = []\n",
        "\n",
        "for i in my_cat_list:\n",
        "  hnet_URL = f\"https://www.h-net.org/jobs/job_browse.php?category_id={i}\"\n",
        "  hnet_page = requests.get(hnet_URL)\n",
        "  hnet_soup = BeautifulSoup(hnet_page.text, \"html.parser\")\n",
        "\n",
        "#CHANGE THE JOB RELASE MONTH In 'string= September 2021'\n",
        "  if hnet_soup.find(name='p', string='September 2021'):\n",
        "    month_post = hnet_soup.find(name='p', string='September 2021').next_sibling.next_sibling\n",
        "  else: pass\n",
        "  \n",
        "  for a in month_post.find_all(name='a'):\n",
        "    institution.append(a.parent.next_element.replace(\", \", \"\"))\n",
        "    position.append(a.text)\n",
        "    link.append('https://www.h-net.org/jobs/' + a['href'])\n",
        "\n",
        "    date_str = a.find_next('span')['title']\n",
        "    date = datetime.strptime(date_str, '%A, %d %B %Y, %X %p').date()\n",
        "    post_date.append(date)\n",
        "\n",
        "d = {'Institution':institution, 'Position': position, 'Link': link}\n",
        "df_hnet = pd.DataFrame(d)\n",
        "df_hnet = df_hnet.drop_duplicates(subset=['Link'])\n",
        "\n",
        "df_hnet = df_hnet.reset_index(drop=True)\n",
        "df_hnet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCdcY0Is1fqj"
      },
      "source": [
        "### 2. Higher Ed Jobs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWgiTmA-fOLw"
      },
      "source": [
        "# server checks headers & change configuration to bypass the blockage\n",
        "keyword_list = ['chinese+or+asian','film+or+media','art+or+art+history','humanities+postdoc']\n",
        "\n",
        "# CHANGE KEY WORDS MANUALLY\n",
        "keyword = keyword_list[0]\n",
        "\n",
        "def get_page_source(n):\n",
        "    url = f'https://www.higheredjobs.com/search/advanced_action.cfm?Keyword={keyword}&JobCat=152&JobCat=131&JobCat=82&JobCat=76&JobCat=157&JobCat=204&JobCat=97&PosType=1&InstType=1&Remote=1&Region=&Submit=Search+Jobs&SortBy=1&NumJobs=100&CatType='\n",
        "    headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
        "    response = requests.get(url, headers=headers)\n",
        "    return response.text\n",
        "\n",
        "n = 1006233\n",
        "text = get_page_source(n)\n",
        "ied_soup = BeautifulSoup(text, \"html.parser\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqeOX0bC2Hg7"
      },
      "source": [
        "institution = []\n",
        "position = []\n",
        "link = []\n",
        "discipline = []\n",
        "deadline = []\n",
        "post_date = []\n",
        "\n",
        "#CHANGE THE SEARCH LIMIT IN \"limit=\" IF NECCESSARY\n",
        "for div in ied_soup.find_all(name='div', attrs={'class':'row record'}):\n",
        "  institution.append(div.find_next('br').next_element.strip())\n",
        "  position.append(div.find_next('a').text.strip())\n",
        "  link.append('https://www.higheredjobs.com/search/' + div.find_next('a')['href'])\n",
        "  discipline.append(div.find_next(name='div', attrs={'class':'col-sm-5 text-sm-right'}).next_element.strip())\n",
        "\n",
        "  date_1 = div.find_next(name='div', attrs={'class':'col-sm-5 text-sm-right'}).find_next('br').next_element.strip()\n",
        "  date_1 = date_1.replace('Posted ','').strip()\n",
        "  date_1 = datetime.strptime(date_1,'%m/%d/%y')\n",
        "  post_date.append(date_1)\n",
        "\n",
        "d = {'Institution':institution, 'Position': position, 'Posting Date':post_date, 'Link': link, 'Discipline': discipline}\n",
        "df_ied = pd.DataFrame(d)\n",
        "df_ied = df_ied.drop_duplicates(subset=['Link'])\n",
        "\n",
        "df_ied = df_ied.reset_index(drop=True)\n",
        "df_ied"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-vJ1VqWIBll"
      },
      "source": [
        "#SELECT THE INDEX NUMBER FROM THE LIST ABOVE\n",
        "select_list = []\n",
        "\n",
        "#CHANGE THE NUMBERING FOR EACH KEYWORD SEARCH\n",
        "df_ied_4 = df_ied.iloc[select_list]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vXVpAN7DIaV"
      },
      "source": [
        "### 3. The Chronicle of Higher Education"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrL2o71uedJL"
      },
      "source": [
        "#CHANGE THE KEYWORDS IN 'my_keyword='\n",
        "keyword_list = ['chinese+or+asian','film+or+media','media+art']\n",
        "\n",
        "institution = []\n",
        "position = []\n",
        "link = []\n",
        "deadline=[]\n",
        "discipline = []\n",
        "post_date = []\n",
        "\n",
        "# POSITION SEARCH\n",
        "for keyword in keyword_list:\n",
        "  che_URL = f\"https://jobs.chronicle.com/searchjobs/?Keywords={keyword}&radialtown=&LocationId=&RadialLocation=20&CountryCode=&PositionType=53&PositionType=56&EmploymentLevel=170&EmploymentLevel=173&EmploymentLevel=175&EmploymentLevel=177&EmploymentType=189\"\n",
        "  che_page = requests.get(che_URL)\n",
        "  che_soup = BeautifulSoup(che_page.text,\"html.parser\")\n",
        "\n",
        "  for li in che_soup.find_all(name='li', attrs={'class':'lister__item cf lister__item--display-logo-on-listing lister__item--display-logo-on-listing'}):\n",
        "    position.append(li.find_next('a').text)\n",
        "    institution.append(li.find_next(name='li',attrs={'class':'lister__meta-item lister__meta-item--recruiter'}).text)\n",
        "    link.append('https://jobs.chronicle.com'+li.find_next('a')['href'].strip())\n",
        "\n",
        "# POSTDOC SEARCH\n",
        "che_URL='https://jobs.chronicle.com/searchjobs/?Keywords=humanities&radialtown=&LocationId=&RadialLocation=20&CountryCode=&PositionType=53&PositionType=56&EmploymentLevel=175&EmploymentType=189'\n",
        "che_page = requests.get(che_URL)\n",
        "che_soup = BeautifulSoup(che_page.text,\"html.parser\")\n",
        "\n",
        "for li in che_soup.find_all(name='li', attrs={'class':'lister__item cf lister__item--display-logo-on-listing lister__item--display-logo-on-listing'}):\n",
        "  position.append(li.find_next('a').text)\n",
        "  institution.append(li.find_next(name='li',attrs={'class':'lister__meta-item lister__meta-item--recruiter'}).text)\n",
        "  link.append('https://jobs.chronicle.com'+li.find_next('a')['href'].strip())\n",
        "\n",
        "d = {'Institution':institution, 'Position': position, 'Link': link}\n",
        "df_che = pd.DataFrame(d)\n",
        "df_che = df_che.drop_duplicates(subset=['Link'])\n",
        "df_che = df_che.reset_index(drop=True)\n",
        "df_che"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRH2W9Vbf8uw"
      },
      "source": [
        "#SELECT THE INDEX NUMBER FROM THE LIST ABOVE\n",
        "select_list = []\n",
        "df_che = df_che.iloc[select_list]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqAfF500KDUw"
      },
      "source": [
        "### 3.5 Inside Higher Education"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0MR5mruX1q9"
      },
      "source": [
        "#CHANGE THE KEYWORDS IN 'my_keyword='\n",
        "my_keyword = ['chinese or asian','film or media','art or art history','humanities postdoc']\n",
        "\n",
        "result = pd.DataFrame()\n",
        "\n",
        "institution = []\n",
        "position = []\n",
        "link = []\n",
        "deadline=[]\n",
        "discipline = []\n",
        "post_date = []\n",
        "\n",
        "#CHANGE THE URL SEARCH CODE IN \"ihe_URL=\" IF NECCESSARY\n",
        "for keyword in my_keyword:\n",
        "  ihe_URL = f\"https://careers.insidehighered.com/searchjobs/?Keywords={keyword}&radialtown=&LocationId=&RadialLocation=20&NearFacetsShown=true&CountryCode=&FacultyJobs=1&SpecialFilters=513023&SpecialFilters=125&SpecialFilters=127&EmploymentType=129&sort=Date\"\n",
        "  ihe_page = requests.get(ihe_URL)\n",
        "  ihe_soup = BeautifulSoup(ihe_page.text, \"html.parser\")\n",
        "\n",
        "#CHANGE THE SEARCH LIMIT IN \"limit=\" IF NECCESSARY\n",
        "  for li in ihe_soup.find_all(name='li', attrs={'class':'lister__meta-item lister__meta-item--recruiter'})[3:]:\n",
        "    institution.append(li.text)\n",
        "    discipline.append(keyword)\n",
        "\n",
        "  for h in ihe_soup.find_all(name='h3', attrs={'class':'lister__header'})[3:]:\n",
        "    position.append(h.text)\n",
        "    link.append('https://careers.insidehighered.com' + h.next['href'].strip())\n",
        "    \n",
        "d = {'Institution':institution, 'Position': position,'Link': link, 'Discipline':discipline}\n",
        "df_ihe = pd.DataFrame(d)\n",
        "df_ihe = df_ihe.drop_duplicates(subset=['Link'])\n",
        "df_ihe=df_ihe.reset_index(drop=True)\n",
        "\n",
        "df_ihe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJBUa3sLqGTe"
      },
      "source": [
        "### 4. Save to Spreadsheet\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TA00HfyYs4fj"
      },
      "source": [
        "from datetime import date\n",
        "\n",
        "today = str(date.today())\n",
        "\n",
        "df_final = pd.DataFrame()\n",
        "df_list = [df_hnet,df_ied_1, df_ied_2, df_ied_3,df_che]\n",
        "\n",
        "for i in df_list:\n",
        "  df_final=df_final.append(i)\n",
        "\n",
        "df_final.to_csv(f'serach_result_{today}.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqI1zRGVcCgg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "115665fb-0393-4e24-95de-53698c7f4c7d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('drive')\n",
        "\n",
        "#CHANGE THE FILE NAME\n",
        "!cp serach_result_2021-09-17.csv 'drive/My Drive/job_search'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBqQd2Rlaag5"
      },
      "source": [
        "### 5. Other Sources\n",
        "\n",
        "* Academic Jobs Wiki (no longer actively maintained)\n",
        "* HERC (not correctly configured server)\n",
        "* Indeed (not exclusively for academic jobs)\n"
      ]
    }
  ]
}