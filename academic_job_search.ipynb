{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "job_list.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZNwP8FpqREp"
      },
      "source": [
        "# Academic Job Search Automation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbIDO0tjIgHo"
      },
      "source": [
        "# Importing necessary libraries\n",
        "import requests\n",
        "import json\n",
        "import bs4\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import time\n",
        "from IPython.core.display import Pretty\n",
        "from datetime import datetime\n",
        "\n",
        "# Setting display options for pandas DataFrames\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "pd.set_option('display.max_rows', 200)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wN4f_k3DX7de"
      },
      "source": [
        "### 1. H-Net Job Guide"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ask the user to enter a custom month and year\n",
        "custom_month_year = input(\"Please enter the month and year (e.g., 'July 2023'): \")\n",
        "\n",
        "hnet_URL = \"https://www.h-net.org/jobs/job_browse.php\"\n",
        "hnet_page = requests.get(hnet_URL)\n",
        "hnet_soup = BeautifulSoup(hnet_page.text, \"html.parser\")\n",
        "\n",
        "institution = []\n",
        "position = []\n",
        "link = []\n",
        "post_date = []\n",
        "\n",
        "# Use the custom month and year entered by the user\n",
        "if hnet_soup.find(name='p', string=custom_month_year):\n",
        "    month_post = hnet_soup.find(name='p', string=custom_month_year).next_sibling.next_sibling\n",
        "else:\n",
        "    print(f\"No postings found for {custom_month_year}.\")\n",
        "    month_post = None\n",
        "\n",
        "if month_post:\n",
        "    for a in month_post.find_all(name='a'):\n",
        "        institution.append(a.parent.next_element.replace(\", \", \"\"))\n",
        "        position.append(a.text)\n",
        "        link.append('https://www.h-net.org/jobs/' + a['href'])\n",
        "\n",
        "        date_str = a.find_next('span')['title']\n",
        "        date = datetime.strptime(date_str, '%A, %d %B %Y, %X %p').date()\n",
        "        post_date.append(date)\n",
        "\n",
        "    d = {'Institution': institution, 'Position': position, 'Link': link, 'Posting Date': post_date}\n",
        "    df_hnet = pd.DataFrame(d)\n",
        "    df_hnet = df_hnet.drop_duplicates(subset=['Link'])\n",
        "\n",
        "    df_hnet = df_hnet.reset_index(drop=True)\n",
        "    print(\"See Below.\")\n",
        "else:\n",
        "    print(\"No data to display.\")\n",
        "\n",
        "df_hnet.head(100)"
      ],
      "metadata": {
        "id": "pSImnSShYgQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt the user to input the select_list index\n",
        "input_indices = input(\"Please enter the index numbers separated by commas (e.g., '1,5,8'): \")\n",
        "select_list = [int(index.strip()) for index in input_indices.split(\",\")]\n",
        "\n",
        "# Filter df_hnet using the select_list\n",
        "df_hnet = df_hnet.iloc[select_list]\n",
        "\n",
        "deadline = []\n",
        "discipline = []\n",
        "\n",
        "for i in list(df_hnet['Link']):\n",
        "    post = requests.get(i)\n",
        "    post_soup = BeautifulSoup(post.text, \"html.parser\")\n",
        "    td1 = post_soup.find('td', string='Closing Date')\n",
        "    date_str = td1.find_next().text\n",
        "    date = datetime.strptime(date_str, '%m/%d/%Y')\n",
        "    deadline.append(date)\n",
        "\n",
        "    td3 = post_soup.find('td', string='Primary Category:')\n",
        "    discipline.append(td3.find_next().text)\n",
        "\n",
        "d = {'Deadline': deadline, 'Discipline': discipline}\n",
        "df_hnet_add = pd.DataFrame(d)\n",
        "\n",
        "df_hnet = df_hnet.reset_index(drop=True)\n",
        "df_select_hnet = pd.concat([df_hnet, df_hnet_add], axis=1)\n",
        "df_select_hnet"
      ],
      "metadata": {
        "id": "lHQhrHDXa01K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCdcY0Is1fqj"
      },
      "source": [
        "### 2. Higher Ed Jobs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display keyword options to the user\n",
        "keyword_list = ['chinese+or+asian', 'film+or+media', 'art+or+art+history', 'comparative+literature', 'humanities+or+liberal+arts']\n",
        "\n",
        "print(\"Available keywords:\")\n",
        "for idx, keyword in enumerate(keyword_list, 1):\n",
        "    print(f\"{idx}. {keyword.replace('+', ' ')}\")\n",
        "\n",
        "# Prompt user for keyword selection or custom input\n",
        "choice = input(\"Select a number from the list above or type a custom keyword (use '+' to connect words): \")\n",
        "\n",
        "# Determine the keyword based on user input\n",
        "if choice.isdigit() and 1 <= int(choice) <= len(keyword_list):\n",
        "    keyword = keyword_list[int(choice) - 1]\n",
        "else:\n",
        "    keyword = choice\n",
        "\n",
        "# Server checks headers & change configuration to bypass the blockage\n",
        "def get_page_source(n):\n",
        "    url = f'https://www.higheredjobs.com/search/advanced_action.cfm?Keyword={keyword}&JobCat=152&JobCat=131&JobCat=82&JobCat=76&JobCat=157&JobCat=204&JobCat=97&PosType=1&InstType=1&Remote=1&Region=&Submit=Search+Jobs&SortBy=1&NumJobs=100&CatType='\n",
        "    headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
        "    response = requests.get(url, headers=headers)\n",
        "    return response.text\n",
        "\n",
        "n = 1006233\n",
        "text = get_page_source(n)\n",
        "ied_soup = BeautifulSoup(text, \"html.parser\")"
      ],
      "metadata": {
        "id": "UZvf_G3OcmAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "institution = []\n",
        "position = []\n",
        "link = []\n",
        "discipline = []\n",
        "deadline = []\n",
        "post_date = []\n",
        "\n",
        "# Extract data from the soup\n",
        "for div in ied_soup.find_all(name='div', attrs={'class':'row record'}):\n",
        "    institution.append(div.find_next('br').next_element.strip())\n",
        "    position.append(div.find_next('a').text.strip())\n",
        "    link.append('https://www.higheredjobs.com/search/' + div.find_next('a')['href'])\n",
        "    discipline.append(div.find_next(name='div', attrs={'class':'col-sm-5 text-sm-right'}).next_element.strip())\n",
        "\n",
        "    date_1 = div.find_next(name='div', attrs={'class':'col-sm-5 text-sm-right'}).find_next('br').next_element.strip()\n",
        "    date_1 = date_1.replace('Posted ','').strip()\n",
        "    date_1 = datetime.strptime(date_1,'%m/%d/%y')\n",
        "    post_date.append(date_1)\n",
        "\n",
        "d = {'Institution': institution, 'Position': position, 'Posting Date': post_date, 'Discipline': discipline,'Link': link}\n",
        "df_ied = pd.DataFrame(d)\n",
        "df_ied = df_ied.drop_duplicates(subset=['Link'])\n",
        "\n",
        "# Ask the user for a posting date\n",
        "user_date_input = input(\"Enter a posting date (in the format MM/DD/YY) to filter out jobs posted before this date: \")\n",
        "user_date = datetime.strptime(user_date_input, '%m/%d/%y')\n",
        "\n",
        "# Filter the dataframe to only include rows with posting dates on or after the user-specified date\n",
        "df_ied = df_ied[df_ied['Posting Date'] >= user_date]\n",
        "\n",
        "df_ied = df_ied.reset_index(drop=True)\n",
        "df_ied"
      ],
      "metadata": {
        "id": "jyCqpXRJdlIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-vJ1VqWIBll",
        "outputId": "8a255f9a-5df0-4829-9e2f-752464916c06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Prompt the user to input the select_list index\n",
        "input_indices = input(\"Please enter the index numbers separated by commas (e.g., '2,4'): \")\n",
        "select_list = [int(index.strip()) for index in input_indices.split(\",\")]\n",
        "\n",
        "# Filter df_ied using the select_list\n",
        "selected_df = df_ied.iloc[select_list]\n",
        "\n",
        "# Extract the first word from the previously selected keyword\n",
        "first_keyword = keyword.split('+')[0]\n",
        "\n",
        "# Rename the dataframe\n",
        "df_name = f\"df_select_ied_{first_keyword}\"\n",
        "locals()[df_name] = selected_df\n",
        "\n",
        "selected_df"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please enter the index numbers separated by commas (e.g., '2,4'): 2,4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vXVpAN7DIaV"
      },
      "source": [
        "### 3. The Chronicle of Higher Education"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrL2o71uedJL"
      },
      "source": [
        "# Display pre-saved keywords\n",
        "keyword_list = ['chinese+or+asian', 'film+or+media', 'art+or+art+history', 'comparative+literature', 'humanities+or+liberal+arts']\n",
        "print(\"Current keywords:\", [keyword.replace('+', ' ') for keyword in keyword_list])\n",
        "\n",
        "# Ask user if they want to replace keywords\n",
        "new_keywords = input(\"Do you want to replace the keywords? If yes, input the new keywords separated by commas. If no, press Enter: \")\n",
        "\n",
        "# If user provides new keywords, update the keyword_list\n",
        "if new_keywords:\n",
        "    keyword_list = [keyword.strip().replace(' ', '+') for keyword in new_keywords.split(',')]\n",
        "\n",
        "institution = []\n",
        "position = []\n",
        "link = []\n",
        "\n",
        "# POSITION SEARCH\n",
        "for keyword in keyword_list:\n",
        "    che_URL = f\"https://jobs.chronicle.com/searchjobs/?Keywords={keyword}&radialtown=&LocationId=&RadialLocation=20&CountryCode=&PositionType=53&PositionType=56&EmploymentLevel=170&EmploymentLevel=173&EmploymentLevel=175&EmploymentLevel=177&EmploymentType=189&sort=Date\"\n",
        "    che_page = requests.get(che_URL)\n",
        "    che_soup = BeautifulSoup(che_page.text, \"html.parser\")\n",
        "\n",
        "    for li in che_soup.find_all(name='li', attrs={'class':'lister__item cf lister__item--display-logo-on-listing lister__item--display-logo-on-listing'}):\n",
        "        position.append(li.find_next('a').text)\n",
        "        institution.append(li.find_next(name='li', attrs={'class':'lister__meta-item lister__meta-item--recruiter'}).text)\n",
        "        link.append('https://jobs.chronicle.com' + li.find_next('a')['href'].strip())\n",
        "\n",
        "d = {'Institution': institution, 'Position': position, 'Link': link}\n",
        "df_che = pd.DataFrame(d)\n",
        "df_che = df_che.drop_duplicates(subset=['Link'])\n",
        "df_che = df_che.reset_index(drop=True)\n",
        "df_che"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ask the user to input the index numbers they want to select\n",
        "select_input = input(\"Please input the index numbers you want to select from the list above, separated by commas (e.g., 4,17): \")\n",
        "\n",
        "# Convert the input string to a list of integers\n",
        "select_list = [int(index.strip()) for index in select_input.split(',')]\n",
        "\n",
        "# Select the rows based on the provided index numbers\n",
        "df_select_che = df_che.iloc[select_list]\n",
        "\n",
        "# Display the selected dataframe\n",
        "df_select_che"
      ],
      "metadata": {
        "id": "IsvssGTos1kP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJBUa3sLqGTe"
      },
      "source": [
        "### 4. Save to Spreadsheet\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import date\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "\n",
        "today = str(date.today())\n",
        "\n",
        "# automatically gather all dataframes that start with \"df_select\"\n",
        "df_list = [value for name, value in globals().items() if name.startswith(\"df_select\")]\n",
        "\n",
        "# using concat to merge the dataframes\n",
        "df_final = pd.concat(df_list, ignore_index=True)\n",
        "df_final.to_csv(f'search_result_{today}.csv', index=False)\n",
        "\n",
        "# mount the file to google drive\n",
        "drive.mount('drive')\n",
        "\n",
        "# use the current date in the filename\n",
        "filename = f\"search_result_{today}.csv\"\n",
        "\n",
        "# opy the file to the specified location\n",
        "!cp $filename 'drive/My Drive/job_search'"
      ],
      "metadata": {
        "id": "dtk4J8GQiAEB",
        "outputId": "56ef4d11-c035-4f7b-81be-337f78148052",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at drive; to attempt to forcibly remount, call drive.mount(\"drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBqQd2Rlaag5"
      },
      "source": [
        "### 5. Other Sources\n",
        "\n",
        "* Academic Jobs Wiki (no longer actively maintained)\n",
        "* Inside Higher Ed Careers (not allowed)\n",
        "* HERC (not correctly configured server)\n",
        "* Indeed (not exclusively for academic jobs)\n"
      ]
    }
  ]
}